\newpage
\section{Анализ предметной области}
\label{sec:Background}

\subsection{Описание предметной области}
Обзор временных рядов, сниппетов временных рядов, а также алгоритмов поиска данных сниппетов во временном ряде.
\vspace{2em}
\subsection{Анализ аналогичных проектов}
Наиболее близким аналогом является работа японских исследователей~\cite{WatanabeG20}, в которой для выделения из текста песни куплетов и припевов используется модель, основанная на обученной нейронной сети. Данная нейронная сеть анализирует девять матриц самоподобия, составленных на основе текста песни.

После того как были созданы матрицы самоподобия, высчитываются векторы признаков с помощью сверточной нейронной сети. Данные векторы используются двунаправленными сетями с длительной кратковременной памятью для разметки текста песни.

Анализ текста используется не только для выделения припевов и куплетов, но также для распознавания жанра песни, как в работе австрийских исследователей~\cite{Genre}. В данной работе предложено создание набора десяти различных признаков на основе текста песни и последующий их анализ с помощью алгоритмов классификации, таких как: случайный лес, метод опорных векторов и нейронной сети с прямой связью.

Еще одним способом выделения куплетов и припевов является анализ звуковых дорожек песен. Данный способ является более исследованным, чем анализ текста.

Например, модель `DeepChorus'~\cite{DeepChorus}, которая использует сочетание многомасштабной сверточной сети для получения предварительной разметки и сверточной нейронной сети с механизмом внутреннего внимания для обработки признаков в кривые вероятности, представляющие присутствие припева. Чтобы получить окончательные результаты, применяется адаптивный порог для бинаризации исходной кривой.

Другая модель `LA-Chorus'~\cite{LA-Chorus} основана на увеличении скрытых функций и архитектуре ResNetFPN. Во-первых, предлагается метод неявного увеличения данных припева в скрытом пространстве на этапе обучения. Во-вторых, применяется нейронная сеть (FPN) для генерации дополнительных признаков от низкой размерности к высокой размерности, достигая многомасштабной парадигмы обучения. 

Модель `MMCR' (Multi-Modal Chorus Recognition)~\cite{MMCR} анализирует одновременно и текс песни, и аудиосигнал. Каждой строке текста ($S_i$) сопоставлена часть аудиосигнала ($A_i$). Информация о $A_i$ представляется в виде мел-кепстральные коэффициентов (MFCC). Информация о $S_i$ получается с помощью
предварительно обученной языковой модели и графовой нейронной сети (Graph Attention Networks). После получения конечной характеристики $F_i$, основанной на соответствующей информации о тексе и аудиосигнале, используется классификатор, чтобы предсказать, принадлежит ли ($A_i$, $S_i$) припеву.

В следующей работе~\cite{ByteDance} так же используется сверточная нейронная сеть. На вход данной нейронной сети поступает мел-спектрограмма песни. После обработки данных нейронной сетью необходимо так же как и в модели `DeepChorus'~\cite{DeepChorus} происходит бинаризация полученных результатов. Конечные данные показывают, к какому разделу песни относится каждый из отрывков.

Ещё один алгоритм выделения припева песни~\cite{OdPlsa} основан на способе вероятностного латентного семантического анализа, зависящего от октавы. Данный способ так же как и предыдущий~\cite{ByteDance} использует для анализа спектрограмму песни и на ее основе составляет матрицы сходства для выделения из них фрагментов припевов.

Представить структуру песни можно и с помощью цветовой карты~\cite{ColorMap}. Чтобы построить её, для каждого аудиокадра вычисляются векторы трех признаков: интенсивность, верхняя и нижняя полоса в частотной области, которые сопоставляются с цветовым пространством RGB. Далее используются мел-кепстральные коэффициенты (MFCC) и алгоритм адоптивной кластеризации сегментации цветного изображения для выделения частей с одинаковым распределением цветов. 

Все вышеописанные методы разделяли только припевы и куплеты, тогда как в работе исследователей из Технологического института Джорджии, США~\cite{Georgia} представлена модель способная классифицировать фрагменты песен по семи разным категориям (вступление, куплет, припев, бридж, концовка, инструментальный проигрыш и тишина). Данная модель основана на использовании спектрально-временного трансформера под названием `SpecTNT'. 

Выделение одних частей звукового сигнала от других используется не только для разделения песни на припевы и куплеты, но и применяется в других сферах деятельности человека. Так, например, основанный на энтропии подход~\cite{Fish} помогает выделять звуки, издаваемые рыбами, среди всех остальных антропогенных шумов. Благодаря этому имеется возможность точно оценить популяцию исследуемых рыб.


